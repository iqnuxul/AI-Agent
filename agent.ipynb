{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq36xdhtmhmt",
        "outputId": "7c1c2354-2055-4da1-bb49-d58ad08de3f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set path (adjust according to your Colab Drive path)\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/'\n",
        "\n",
        "# Load scaler\n",
        "with open(base_path + 'scaler2.pkl', 'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "# Load input feature columns\n",
        "with open(base_path + 'input_columns.json', 'r') as f:\n",
        "    input_columns = json.load(f)\n",
        "input_dim = len(input_columns)\n",
        "\n",
        "# Define model architecture\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(self.relu(self.fc2(x)))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Initialize model and load parameters\n",
        "model = MLP(input_dim)\n",
        "model.load_state_dict(torch.load(base_path + \"mlp_model.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dN8lpsim-9N",
        "outputId": "6d175982-12ac-4c62-99a2-b6e2f1b1bdf6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=22, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-openai openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4kYITYtRN9y",
        "outputId": "4a328249-dc76-49b3-d2e9-f01e3e80a2a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.17-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.17-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.3.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_tool.py\n",
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Union\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Preprocess input\n",
        "def preprocess_input(data: pd.DataFrame) -> torch.Tensor:\n",
        "    for col in input_columns:\n",
        "        if col not in data.columns:\n",
        "            data[col] = 0\n",
        "    data = data[input_columns]\n",
        "    scaled = scaler.transform(data)\n",
        "    return torch.tensor(scaled, dtype=torch.float32)\n",
        "\n",
        "import ast  # Safely parse string to Python object\n",
        "\n",
        "def predict_sales(store_data: Union[str, List[Dict], Dict]) -> list:\n",
        "    if isinstance(store_data, str):\n",
        "        try:\n",
        "            store_data = ast.literal_eval(store_data)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Failed to parse input string to dictionary: {e}\")\n",
        "\n",
        "    if isinstance(store_data, dict):\n",
        "        store_data = [store_data]\n",
        "    elif not isinstance(store_data, list):\n",
        "        raise ValueError(\"store_data must be a dict or list of dicts.\")\n",
        "\n",
        "    df = pd.DataFrame(store_data)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df[\"Year\"] = df[\"Date\"].dt.year\n",
        "    df[\"Month\"] = df[\"Date\"].dt.month\n",
        "    df[\"Day\"] = df[\"Date\"].dt.day\n",
        "    df.fillna(0, inplace=True)\n",
        "    input_tensor = preprocess_input(df)\n",
        "    with torch.no_grad():\n",
        "        preds = model(input_tensor).squeeze().tolist()\n",
        "    return preds if isinstance(preds, list) else [preds]\n",
        "\n",
        "# LangChain-compatible version of the promotion recommendation tool\n",
        "def recommend_promotions(data: dict) -> dict:\n",
        "    if isinstance(data, str):\n",
        "        data = json.loads(data)\n",
        "    store_list = data[\"store_ids\"]\n",
        "    date = data[\"date\"]\n",
        "\n",
        "    recommendation = {}\n",
        "    today = pd.to_datetime(date)\n",
        "    weekday = today.dayofweek + 1\n",
        "\n",
        "    input_data = []\n",
        "    for store in store_list:\n",
        "        for promo in [0, 1]:\n",
        "            input_data.append({\n",
        "                \"Store\": store,\n",
        "                \"Date\": date,\n",
        "                \"Promo\": promo,\n",
        "                \"DayOfWeek\": weekday,\n",
        "                \"Open\": 1,\n",
        "                # \"Customers\": 500  # Optionally assume default customers\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(input_data)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df[\"Year\"] = df[\"Date\"].dt.year\n",
        "    df[\"Month\"] = df[\"Date\"].dt.month\n",
        "    df[\"Day\"] = df[\"Date\"].dt.day\n",
        "\n",
        "    input_tensor = preprocess_input(df)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(input_tensor).squeeze().tolist()\n",
        "\n",
        "    for i, store in enumerate(store_list):\n",
        "        no_promo = preds[i * 2]\n",
        "        with_promo = preds[i * 2 + 1]\n",
        "        recommendation[store] = \"Promotion recommended\" if with_promo - no_promo > 300 else \"No promotion needed\"\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "# Wrap with Tool\n",
        "predict_sales_tool = Tool.from_function(\n",
        "    func=predict_sales,\n",
        "    name=\"predict_sales\",\n",
        "    description=(\n",
        "        \"Predict sales based on store data. \"\n",
        "        \"Input should be a dict or a list of dicts, each with: Store, Date (YYYY-MM-DD), Promo, DayOfWeek, Open\"\n",
        "    )\n",
        ")\n",
        "\n",
        "recommend_promotions_tool = Tool.from_function(\n",
        "    func=recommend_promotions,\n",
        "    name=\"recommend_promotions\",\n",
        "    description=(\n",
        "        \"Recommend promotion strategies for stores. \"\n",
        "        \"Input is a dict with a list of store IDs like [1, 2] and a date string like '2015-07-10'\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Initialize Agent\n",
        "agent = initialize_agent(\n",
        "    tools=[predict_sales_tool, recommend_promotions_tool],\n",
        "    llm=llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Test call (input must be structured)\n",
        "# print(agent.invoke(\"What is the predicted sales for store 1 on 2016-07-31?\"))\n",
        "print(agent.invoke(\"Should store 1 and 2 do promotions on 2016-12-22?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7GteGyznwSm",
        "outputId": "7eb3fdd7-46ea-49d0-9791-4486586d82eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-eac83d706c4d>:110: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo determine if stores 1 and 2 should do promotions on 2016-12-22, I need to recommend promotion strategies for these stores on that date.\n",
            "\n",
            "Action: recommend_promotions\n",
            "Action Input: {\"store_ids\": [1, 2], \"date\": \"2016-12-22\"}\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m{1: 'Promotion recommended', 2: 'Promotion recommended'}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mBoth stores 1 and 2 are recommended to do promotions on 2016-12-22.\n",
            "\n",
            "Final Answer: Yes, both store 1 and store 2 should do promotions on 2016-12-22.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'Should store 1 and 2 do promotions on 2016-12-22?', 'output': 'Yes, both store 1 and store 2 should do promotions on 2016-12-22.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"secret\"\n"
      ],
      "metadata": {
        "id": "AHuk-lD3tN5V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88JRo17XxUpo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}