{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-12T19:52:14.611267Z",
     "iopub.status.busy": "2025-05-12T19:52:14.610981Z",
     "iopub.status.idle": "2025-05-12T19:52:14.927508Z",
     "shell.execute_reply": "2025-05-12T19:52:14.926682Z",
     "shell.execute_reply.started": "2025-05-12T19:52:14.611246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/rossmann-store-sales/sample_submission.csv\n",
      "/kaggle/input/rossmann-store-sales/store.csv\n",
      "/kaggle/input/rossmann-store-sales/train.csv\n",
      "/kaggle/input/rossmann-store-sales/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(\n",
    "    '/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T19:52:15.241526Z",
     "iopub.status.busy": "2025-05-12T19:52:15.241132Z",
     "iopub.status.idle": "2025-05-12T19:59:40.166108Z",
     "shell.execute_reply": "2025-05-12T19:59:40.165175Z",
     "shell.execute_reply.started": "2025-05-12T19:52:15.241459Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1166.65, Val RMSE: 1288.26, R²: 0.8884\n",
      "Epoch 2, Train Loss: 805.91, Val RMSE: 1212.86, R²: 0.9011\n",
      "Epoch 3, Train Loss: 776.37, Val RMSE: 1168.89, R²: 0.9081\n",
      "Epoch 4, Train Loss: 754.07, Val RMSE: 1124.64, R²: 0.9149\n",
      "Epoch 5, Train Loss: 738.89, Val RMSE: 1093.91, R²: 0.9195\n",
      "Epoch 6, Train Loss: 728.54, Val RMSE: 1076.93, R²: 0.9220\n",
      "Epoch 7, Train Loss: 719.33, Val RMSE: 1058.27, R²: 0.9247\n",
      "Epoch 8, Train Loss: 712.02, Val RMSE: 1040.29, R²: 0.9272\n",
      "Epoch 9, Train Loss: 703.96, Val RMSE: 1022.87, R²: 0.9296\n",
      "Epoch 10, Train Loss: 696.93, Val RMSE: 1006.85, R²: 0.9318\n",
      "Epoch 11, Train Loss: 690.06, Val RMSE: 992.05, R²: 0.9338\n",
      "Epoch 12, Train Loss: 683.85, Val RMSE: 978.86, R²: 0.9355\n",
      "Epoch 13, Train Loss: 677.33, Val RMSE: 963.40, R²: 0.9376\n",
      "Epoch 14, Train Loss: 670.54, Val RMSE: 949.44, R²: 0.9394\n",
      "Epoch 15, Train Loss: 664.64, Val RMSE: 940.01, R²: 0.9406\n",
      "Epoch 16, Train Loss: 658.28, Val RMSE: 922.66, R²: 0.9427\n",
      "Epoch 17, Train Loss: 651.54, Val RMSE: 915.03, R²: 0.9437\n",
      "Epoch 18, Train Loss: 646.92, Val RMSE: 902.47, R²: 0.9452\n",
      "Epoch 19, Train Loss: 643.02, Val RMSE: 893.99, R²: 0.9462\n",
      "\n",
      " MLP Final Evaluation -> MSE: 796908.84, RMSE: 892.70, MAE: 563.77, R^2: 0.9461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Load training data and store information\n",
    "train = pd.read_csv('/kaggle/input/rossmann-store-sales/train.csv', low_memory=False)\n",
    "store = pd.read_csv('/kaggle/input/rossmann-store-sales/store.csv', low_memory=False)\n",
    "data = pd.merge(train, store, on='Store', how='left')\n",
    "\n",
    "# Process date features\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['WeekOfYear'] = data['Date'].dt.isocalendar().week\n",
    "\n",
    "# Fill missing values with 0\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Label encoding for categorical features\n",
    "# turn text to int\n",
    "le = LabelEncoder()\n",
    "data['StoreType'] = le.fit_transform(data['StoreType'])\n",
    "data['Assortment'] = le.fit_transform(data['Assortment'])\n",
    "data['PromoInterval'] = le.fit_transform(data['PromoInterval'].astype(str))\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(['Sales', 'Date'], axis=1)\n",
    "y = data['Sales']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encode 'StateHoliday' column\n",
    "X_train = pd.get_dummies(X_train, columns=['StateHoliday'], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=['StateHoliday'], drop_first=True)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)  # Align columns\n",
    "\n",
    "# Standardize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "\n",
    "# Wrap training data in DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Further split training set into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_final, y_train_final)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train_tensor.shape[1]\n",
    "model = MLP(input_size).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.SmoothL1Loss()  # Also known as Huber Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "early_stop_patience = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 20):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_preds, val_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb).cpu().numpy()\n",
    "            val_preds.extend(preds.flatten())\n",
    "            val_targets.extend(yb.numpy().flatten())\n",
    "\n",
    "    val_mse = mean_squared_error(val_targets, val_preds)\n",
    "    val_rmse = np.sqrt(val_mse)\n",
    "    val_r2 = r2_score(val_targets, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch}, Train Loss: {np.mean(train_losses):.2f}, Val RMSE: {val_rmse:.2f}, R²: {val_r2:.4f}\")\n",
    "\n",
    "    scheduler.step(val_mse)\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_mse < best_val_loss:\n",
    "        best_val_loss = val_mse\n",
    "        early_stop_counter = 0\n",
    "        best_model_state = model.state_dict()\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = model(X_test_tensor.to(device)).cpu().numpy().flatten()\n",
    "    mse = mean_squared_error(y_test, test_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, test_preds)\n",
    "    r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "print(f\"\\n MLP Final Evaluation -> MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R^2: {r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:01:21.930596Z",
     "iopub.status.busy": "2025-05-12T20:01:21.930107Z",
     "iopub.status.idle": "2025-05-12T20:01:21.939804Z",
     "shell.execute_reply": "2025-05-12T20:01:21.938991Z",
     "shell.execute_reply.started": "2025-05-12T20:01:21.930568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'mlp_model.pth')\n",
    "\n",
    "# Save scaler for future standardization\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Save input column names for inference\n",
    "with open('input_columns.json', 'w') as f:\n",
    "    json.dump(X_train.columns.tolist(), f)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 860645,
     "sourceId": 4594,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
