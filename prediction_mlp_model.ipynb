{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4594,"databundleVersionId":860645,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk(\n    '/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T15:00:59.371902Z","iopub.execute_input":"2025-05-18T15:00:59.372348Z","iopub.status.idle":"2025-05-18T15:00:59.696757Z","shell.execute_reply.started":"2025-05-18T15:00:59.372306Z","shell.execute_reply":"2025-05-18T15:00:59.695867Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/rossmann-store-sales/sample_submission.csv\n/kaggle/input/rossmann-store-sales/store.csv\n/kaggle/input/rossmann-store-sales/train.csv\n/kaggle/input/rossmann-store-sales/test.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nimport joblib\n\n# loading data\ntrain = pd.read_csv('/kaggle/input/rossmann-store-sales/train.csv', low_memory=False)\nstore = pd.read_csv('/kaggle/input/rossmann-store-sales/store.csv', low_memory=False)\ndata = pd.merge(train, store, on='Store', how='left')\n\n# date processing\ndata['Date'] = pd.to_datetime(data['Date'])\ndata['Year'] = data['Date'].dt.year\ndata['Month'] = data['Date'].dt.month\ndata['Day'] = data['Date'].dt.day\ndata['WeekOfYear'] = data['Date'].dt.isocalendar().week\n\n# missing value\ndata.fillna(0, inplace=True)\n\n# label encoding\nle = LabelEncoder()\ndata['StoreType'] = le.fit_transform(data['StoreType'])\ndata['Assortment'] = le.fit_transform(data['Assortment'])\ndata['PromoInterval'] = le.fit_transform(data['PromoInterval'].astype(str))\n\n# features and target\nX = data.drop(['Sales', 'Date'], axis=1)\ny = data['Sales']\n\n# split training data and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Onehotencode StateHoliday \nX_train = pd.get_dummies(X_train, columns=['StateHoliday'], drop_first=True)\nX_test = pd.get_dummies(X_test, columns=['StateHoliday'], drop_first=True)\nX_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n\n# standardlize\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n#turn to tensor float\nX_train_tensor = torch.FloatTensor(X_train_scaled)\ny_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\nX_test_tensor = torch.FloatTensor(X_test_scaled)\n\n# data loader\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n\n# 优化后的 MLP\nclass MLP(nn.Module):\n    def __init__(self, input_size):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.dropout = nn.Dropout(0.1)\n        self.fc3 = nn.Linear(64, 1)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.dropout(self.relu(self.fc2(x)))\n        return self.fc3(x)\n\n# 分割验证集\nfrom sklearn.model_selection import train_test_split\nX_train_final, X_val, y_train_final, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.1, random_state=42)\n\ntrain_dataset = TensorDataset(X_train_final, y_train_final)\nval_dataset = TensorDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# 初始化模型\ninput_size = X_train_tensor.shape[1]\nmodel = MLP(input_size).to(device)\n\n# 损失函数和优化器\ncriterion = nn.SmoothL1Loss()  # Huber Loss\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n\n# Early stopping 参数\nbest_val_loss = float('inf')\nearly_stop_counter = 0\nearly_stop_patience = 10\n\n# 训练循环\nfor epoch in range(1, 20):\n    model.train()\n    train_losses = []\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)\n        optimizer.zero_grad()\n        out = model(xb)\n        loss = criterion(out, yb)\n        loss.backward()\n        optimizer.step()\n        train_losses.append(loss.item())\n\n    # 验证\n    model.eval()\n    val_preds, val_targets = [], []\n    with torch.no_grad():\n        for xb, yb in val_loader:\n            xb = xb.to(device)\n            preds = model(xb).cpu().numpy()\n            val_preds.extend(preds.flatten())\n            val_targets.extend(yb.numpy().flatten())\n\n    val_mse = mean_squared_error(val_targets, val_preds)\n    val_rmse = np.sqrt(val_mse)\n    val_r2 = r2_score(val_targets, val_preds)\n\n    print(f\"Epoch {epoch}, Train Loss: {np.mean(train_losses):.2f}, Val RMSE: {val_rmse:.2f}, R²: {val_r2:.4f}\")\n\n    scheduler.step(val_mse)\n\n    # Early stopping 检查\n    if val_mse < best_val_loss:\n        best_val_loss = val_mse\n        early_stop_counter = 0\n        best_model_state = model.state_dict()\n    else:\n        early_stop_counter += 1\n        if early_stop_counter >= early_stop_patience:\n            print(\"Early stopping triggered.\")\n            break\n\n# 加载最佳模型\nmodel.load_state_dict(best_model_state)\n\n# 测试集评估\nmodel.eval()\nwith torch.no_grad():\n    test_preds = model(X_test_tensor.to(device)).cpu().numpy().flatten()\n    mse = mean_squared_error(y_test, test_preds)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_test, test_preds)\n    r2 = r2_score(y_test, test_preds)\n\nprint(f\"\\n MLP Final Evaluation -> MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R^2: {r2:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T15:01:03.339131Z","iopub.execute_input":"2025-05-18T15:01:03.339695Z","iopub.status.idle":"2025-05-18T15:07:59.175379Z","shell.execute_reply.started":"2025-05-18T15:01:03.339652Z","shell.execute_reply":"2025-05-18T15:07:59.174435Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Train Loss: 1178.27, Val RMSE: 1300.99, R²: 0.8861\nEpoch 2, Train Loss: 814.07, Val RMSE: 1222.83, R²: 0.8994\nEpoch 3, Train Loss: 789.33, Val RMSE: 1181.82, R²: 0.9061\nEpoch 4, Train Loss: 768.27, Val RMSE: 1146.40, R²: 0.9116\nEpoch 5, Train Loss: 751.77, Val RMSE: 1110.99, R²: 0.9170\nEpoch 6, Train Loss: 739.71, Val RMSE: 1088.46, R²: 0.9203\nEpoch 7, Train Loss: 730.42, Val RMSE: 1065.24, R²: 0.9237\nEpoch 8, Train Loss: 722.47, Val RMSE: 1051.19, R²: 0.9257\nEpoch 9, Train Loss: 715.63, Val RMSE: 1037.03, R²: 0.9277\nEpoch 10, Train Loss: 709.74, Val RMSE: 1019.84, R²: 0.9300\nEpoch 11, Train Loss: 702.91, Val RMSE: 1008.66, R²: 0.9316\nEpoch 12, Train Loss: 696.63, Val RMSE: 998.64, R²: 0.9329\nEpoch 13, Train Loss: 690.40, Val RMSE: 984.86, R²: 0.9348\nEpoch 14, Train Loss: 684.80, Val RMSE: 971.56, R²: 0.9365\nEpoch 15, Train Loss: 678.67, Val RMSE: 957.19, R²: 0.9384\nEpoch 16, Train Loss: 673.68, Val RMSE: 947.36, R²: 0.9396\nEpoch 17, Train Loss: 667.98, Val RMSE: 939.68, R²: 0.9406\nEpoch 18, Train Loss: 663.27, Val RMSE: 927.35, R²: 0.9422\nEpoch 19, Train Loss: 659.33, Val RMSE: 922.45, R²: 0.9428\n\n MLP Final Evaluation -> MSE: 856268.52, RMSE: 925.35, MAE: 582.87, R^2: 0.9421\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# save\ntorch.save(model.state_dict(), 'mlp_model.pth')\n\n# 保存 scaler，用于对用户输入数据标准化\nimport joblib\n\n# 保存列名（用于之后构造输入）\nimport json\nwith open('input_columns.json', 'w') as f:\n    json.dump(X_train.columns.tolist(), f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T20:01:21.930107Z","iopub.execute_input":"2025-05-12T20:01:21.930596Z","iopub.status.idle":"2025-05-12T20:01:21.939804Z","shell.execute_reply.started":"2025-05-12T20:01:21.930568Z","shell.execute_reply":"2025-05-12T20:01:21.938991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport pickle\nwith open(\"scaler2.pkl\", \"wb\") as f:\n    pickle.dump(scaler, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T15:09:38.189525Z","iopub.execute_input":"2025-05-18T15:09:38.189865Z","iopub.status.idle":"2025-05-18T15:09:38.194574Z","shell.execute_reply.started":"2025-05-18T15:09:38.189835Z","shell.execute_reply":"2025-05-18T15:09:38.193693Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}