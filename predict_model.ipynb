{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4594,"databundleVersionId":860645,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk(\n    '/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:19:13.334950Z","iopub.execute_input":"2025-05-11T16:19:13.335285Z","iopub.status.idle":"2025-05-11T16:19:15.655038Z","shell.execute_reply.started":"2025-05-11T16:19:13.335255Z","shell.execute_reply":"2025-05-11T16:19:15.654316Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/rossmann-store-sales/sample_submission.csv\n/kaggle/input/rossmann-store-sales/store.csv\n/kaggle/input/rossmann-store-sales/train.csv\n/kaggle/input/rossmann-store-sales/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nimport joblib\n\n# loading data\ntrain = pd.read_csv('/kaggle/input/rossmann-store-sales/train.csv', low_memory=False)\nstore = pd.read_csv('/kaggle/input/rossmann-store-sales/store.csv', low_memory=False)\ndata = pd.merge(train, store, on='Store', how='left')\n\n# date processing\ndata['Date'] = pd.to_datetime(data['Date'])\ndata['Year'] = data['Date'].dt.year\ndata['Month'] = data['Date'].dt.month\ndata['Day'] = data['Date'].dt.day\ndata['WeekOfYear'] = data['Date'].dt.isocalendar().week\n\n# missing value\ndata.fillna(0, inplace=True)\n\n# label encoding\nle = LabelEncoder()\ndata['StoreType'] = le.fit_transform(data['StoreType'])\ndata['Assortment'] = le.fit_transform(data['Assortment'])\ndata['PromoInterval'] = le.fit_transform(data['PromoInterval'].astype(str))\n\n# features and target\nX = data.drop(['Sales', 'Date', 'Customers'], axis=1)\ny = data['Sales']\n\n# split training data and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Onehotencode StateHoliday \nX_train = pd.get_dummies(X_train, columns=['StateHoliday'], drop_first=True)\nX_test = pd.get_dummies(X_test, columns=['StateHoliday'], drop_first=True)\nX_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n\n# standardlize\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n#turn to tensor float\nX_train_tensor = torch.FloatTensor(X_train_scaled)\ny_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\nX_test_tensor = torch.FloatTensor(X_test_scaled)\n\n# data loader\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n\n# define MLP model\nclass MLP(nn.Module):\n    def __init__(self, input_size):\n        super(MLP, self).__init__()\n        self.fc1 = nn.Linear(input_size, 200)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(200, 50)\n        self.fc3 = nn.Linear(50, 1)\n\n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.relu(self.fc2(x))\n        return self.fc3(x)\n\n# initialization model\ninput_size = X_train_tensor.shape[1]\nmodel = MLP(input_size)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# criterion and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# training \nnum_epochs = 100\nfor epoch in range(num_epochs):\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# predict and evaluation\nmodel.eval()\nwith torch.no_grad():\n    X_test_tensor = X_test_tensor.to(device)\n    y_pred_tensor = model(X_test_tensor)\n    y_pred = y_pred_tensor.cpu().numpy().flatten()\n\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"MLP Evaluation -> MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R^2: {r2:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:47:15.985353Z","iopub.execute_input":"2025-05-11T16:47:15.985608Z","iopub.status.idle":"2025-05-11T17:25:18.754131Z","shell.execute_reply.started":"2025-05-11T16:47:15.985588Z","shell.execute_reply":"2025-05-11T17:25:18.753365Z"}},"outputs":[{"name":"stdout","text":"Epoch [10/100], Loss: 2481272.7500\nEpoch [20/100], Loss: 2822495.5000\nEpoch [30/100], Loss: 4214482.5000\nEpoch [40/100], Loss: 4587160.0000\nEpoch [50/100], Loss: 1575234.5000\nEpoch [60/100], Loss: 379559.9375\nEpoch [70/100], Loss: 1985745.2500\nEpoch [80/100], Loss: 1177378.6250\nEpoch [90/100], Loss: 5495207.5000\nEpoch [100/100], Loss: 209393.4688\nMLP Evaluation -> MSE: 1682135.75, RMSE: 1296.97, MAE: 879.15, R^2: 0.89\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"feature_names = X_train.columns.tolist()\nprint(feature_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:39:12.199481Z","iopub.execute_input":"2025-05-11T16:39:12.200011Z","iopub.status.idle":"2025-05-11T16:39:12.204667Z","shell.execute_reply.started":"2025-05-11T16:39:12.199979Z","shell.execute_reply":"2025-05-11T16:39:12.203668Z"}},"outputs":[{"name":"stdout","text":"['Store', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'Year', 'Month', 'Day', 'WeekOfYear', 'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"features = ['Store', 'DayOfWeek', 'Open', 'Promo', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'Year', 'Month', 'Day', 'WeekOfYear', 'StateHoliday_a', 'StateHoliday_b', 'StateHoliday_c']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:28:27.501404Z","iopub.execute_input":"2025-05-11T17:28:27.501792Z","iopub.status.idle":"2025-05-11T17:28:27.506202Z","shell.execute_reply.started":"2025-05-11T17:28:27.501762Z","shell.execute_reply":"2025-05-11T17:28:27.505309Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# save\ntorch.save(model.state_dict(), 'mlp_model.pth')\njoblib.dump(scaler, 'scaler.pkl')\njoblib.dump(features, \"features.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:28:46.055180Z","iopub.execute_input":"2025-05-11T17:28:46.055470Z","iopub.status.idle":"2025-05-11T17:28:46.063950Z","shell.execute_reply.started":"2025-05-11T17:28:46.055449Z","shell.execute_reply":"2025-05-11T17:28:46.063129Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['features.pkl']"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Train Random Forest Model\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\nrf_model.fit(X_train, y_train)\n\n# Evaluation\ny_pred_rf = rf_model.predict(X_test)\nmse_rf = mean_squared_error(y_test, y_pred_rf)\nrmse_rf = np.sqrt(mse_rf)\nmae_rf = mean_absolute_error(y_test, y_pred_rf)\nr2_rf = r2_score(y_test, y_pred_rf)\n\nprint(f\"Random Forest - MSE: {mse_rf}, RMSE: {rmse_rf}, MAE: {mae_rf}, R^2: {r2_rf}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T16:44:25.236680Z","iopub.execute_input":"2025-05-11T16:44:25.237072Z","iopub.status.idle":"2025-05-11T16:47:15.984193Z","shell.execute_reply.started":"2025-05-11T16:44:25.237039Z","shell.execute_reply":"2025-05-11T16:47:15.983362Z"}},"outputs":[{"name":"stdout","text":"Random Forest - MSE: 682784.7598545548, RMSE: 826.3079086239916, MAE: 481.7960875827017, R^2: 0.9538309439174449\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# save\ntorch.save(rf_model.state_dict(), 'rf_model.pth')\njoblib.dump(scaler, 'scaler.pkl')\njoblib.dump(feature, \"models/features.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T17:34:01.511627Z","iopub.execute_input":"2025-05-11T17:34:01.511974Z","iopub.status.idle":"2025-05-11T17:34:01.526672Z","shell.execute_reply.started":"2025-05-11T17:34:01.511946Z","shell.execute_reply":"2025-05-11T17:34:01.525498Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-b0f9da281685>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 保存模型与标准化器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rf_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scaler.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/features.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'state_dict'"],"ename":"AttributeError","evalue":"'RandomForestRegressor' object has no attribute 'state_dict'","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}